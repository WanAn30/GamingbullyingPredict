import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate, StratifiedKFold
from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# 读取数据
input_file = "../Data/RF_selected_features_data.csv"
output_file = "../Data/data4_ybl.csv"

try:
    X = pd.read_csv(input_file)
    y = pd.read_csv(output_file).iloc[:, 0]
except Exception as e:
    print(f"Error reading input files: {e}")
    raise

# 检查缺失值
if X.isnull().sum().any() or y.isnull().sum().any():
    print("Warning: Missing values detected. Please handle them before proceeding.")
    # Handle missing values if necessary
    # X.fillna(X.mean(), inplace=True)
    # y.fillna(y.mean(), inplace=True)

# 将输出变量转换为分类变量
y = y.apply(lambda x: 'YES' if x > 9 else 'NO')

# 定义随机森林分类器
rf = RandomForestClassifier(random_state=42)

# 自定义评分函数
scoring = {
    'accuracy': 'accuracy',
    'precision': make_scorer(precision_score, pos_label='YES'),
    'recall': make_scorer(recall_score, pos_label='YES'),
    'f1': make_scorer(f1_score, pos_label='YES'),
    'roc_auc': 'roc_auc'
}

# 进行十折交叉验证
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
print("Starting cross-validation...")
scores = cross_validate(rf, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_estimator=True)

# 打印模型评估指标
accuracy = np.mean(scores['test_accuracy'])
precision = np.mean(scores['test_precision'])
recall = np.mean(scores['test_recall'])
f1 = np.mean(scores['test_f1'])
roc_auc = np.mean(scores['test_roc_auc'])

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"AUC-ROC: {roc_auc:.4f}")

# 保存模型评估指标
metrics_df = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC'],
    'Score': [accuracy, precision, recall, f1, roc_auc]
})

# 训练模型并计算特征重要性
print("Training model...")
rf.fit(X, y)

# 基于MDI方法计算特征重要性
mdi_importances = rf.feature_importances_

# 基于MDA方法计算特征重要性
print("Calculating MDA importances...")
mda_importances = []
n_permutations = 10  # 置换次数

for i in range(X.shape[1]):
    permuted_scores = []
    for _ in range(n_permutations):
        X_permuted = X.copy()
        X_permuted.iloc[:, i] = np.random.permutation(X_permuted.iloc[:, i])
        score = cross_validate(rf, X_permuted, y, cv=cv, scoring='accuracy', n_jobs=-1)
        permuted_scores.append(np.mean(score['test_score']))
    mda_importances.append(np.mean(scores['test_accuracy']) - np.mean(permuted_scores))

# 创建特征重要性数据框
feature_names = X.columns
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'MDI Importance': mdi_importances,
    'MDA Importance': mda_importances
})

# 排序特征重要性
importance_df = importance_df.sort_values(by='MDI Importance', ascending=False)

# 打印特征重要性
print(importance_df)

# 保存特征重要性
output_path = '../OUTPUT/RF/'
with pd.ExcelWriter(f'{output_path}model_evaluation_metrics_and_importances.xlsx') as writer:
    metrics_df.to_excel(writer, sheet_name='Model Evaluation Metrics', index=False)
    importance_df.to_excel(writer, sheet_name='Feature Importances', index=False)

# 绘制特征重要性图
plt.figure(figsize=(12, 8))
sns.barplot(x='MDI Importance', y='Feature', data=importance_df, palette='viridis')
plt.title('Feature Importance based on MDI')
plt.tight_layout()
plt.savefig(f'{output_path}mdi_feature_importance.jpeg', dpi=1000)
plt.show()

plt.figure(figsize=(12, 8))
sns.barplot(x='MDA Importance', y='Feature', data=importance_df.sort_values(by='MDA Importance', ascending=False), palette='viridis')
plt.title('Feature Importance based on MDA')
plt.tight_layout()
plt.savefig(f'{output_path}mda_feature_importance.jpeg', dpi=1000)
plt.show()

# 绘制ROC曲线
print("Plotting ROC curve...")
plt.figure(figsize=(12, 8))
tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)

for i, (train, test) in enumerate(cv.split(X, y)):
    probas_ = scores['estimator'][i].predict_proba(X.iloc[test])
    fpr, tpr, thresholds = roc_curve(y.iloc[test], probas_[:, 1], pos_label='YES')
    tprs.append(np.interp(mean_fpr, fpr, tpr))
    tprs[-1][0] = 0.0
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)
    plt.plot(fpr, tpr, lw=1, alpha=0.3, label=f'ROC fold {i} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8)
mean_tpr = np.mean(tprs, axis=0)
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
std_auc = np.std(aucs)
plt.plot(mean_fpr, mean_tpr, color='b', label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})', lw=2, alpha=0.8)

std_tpr = np.std(tprs, axis=0)
tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.2, label='± 1 std. dev.')

plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.tight_layout()
plt.savefig(f'{output_path}roc_curve.jpeg', dpi=1000)
plt.show()
